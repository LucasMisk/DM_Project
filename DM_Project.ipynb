{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in d:\\anaconda\\envs\\iiotca\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\envs\\iiotca\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: pandas in d:\\anaconda\\envs\\iiotca\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\envs\\iiotca\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\envs\\iiotca\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\envs\\iiotca\\lib\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\envs\\iiotca\\lib\\site-packages (from requests) (2024.6.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\envs\\iiotca\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\anaconda\\envs\\iiotca\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\envs\\iiotca\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\envs\\iiotca\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda\\envs\\iiotca\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\envs\\iiotca\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch torchvision torchaudio"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!conda install pytorch-cuda==11.8 -c pytorch -c nvidia"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in d:\\anaconda\\envs\\iiotca\\lib\\site-packages (2.3.1+cu118)\n",
      "Requirement already satisfied: torchvision in d:\\anaconda\\envs\\iiotca\\lib\\site-packages (0.18.1+cu118)\n",
      "Requirement already satisfied: torchaudio in d:\\anaconda\\envs\\iiotca\\lib\\site-packages (2.3.1+cu118)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pytorch-cuda (from versions: none)\n",
      "ERROR: No matching distribution found for pytorch-cuda\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Band  Genre         Subgenre\n",
      "0           The Beatles   Rock     Classic Rock\n",
      "1    The Rolling Stones   Rock     Classic Rock\n",
      "2               The Who   Rock     Classic Rock\n",
      "3          Led Zeppelin   Rock     Classic Rock\n",
      "4             The Doors   Rock     Classic Rock\n",
      "..                  ...    ...              ...\n",
      "245    Rhapsody of Fire  Metal  Symphonic Metal\n",
      "246              Delain  Metal  Symphonic Metal\n",
      "247        Leaves' Eyes  Metal  Symphonic Metal\n",
      "248             Xandria  Metal  Symphonic Metal\n",
      "249       After Forever  Metal  Symphonic Metal\n",
      "\n",
      "[250 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the bands, genres, and subgenres\n",
    "bands_data = [\n",
    "    (\"The Beatles\", \"Rock\", \"Classic Rock\"),\n",
    "    (\"The Rolling Stones\", \"Rock\", \"Classic Rock\"),\n",
    "    (\"The Who\", \"Rock\", \"Classic Rock\"),\n",
    "    (\"Led Zeppelin\", \"Rock\", \"Classic Rock\"),\n",
    "    (\"The Doors\", \"Rock\", \"Classic Rock\"),\n",
    "    (\"Pink Floyd\", \"Rock\", \"Classic Rock\"),\n",
    "    (\"Queen\", \"Rock\", \"Classic Rock\"),\n",
    "    (\"Creedence Clearwater Revival\", \"Rock\", \"Classic Rock\"),\n",
    "    (\"Jimi Hendrix\", \"Rock\", \"Classic Rock\"),\n",
    "    (\"Deep Purple\", \"Rock\", \"Classic Rock\"),\n",
    "    (\"AC/DC\", \"Rock\", \"Hard Rock\"),\n",
    "    (\"Aerosmith\", \"Rock\", \"Hard Rock\"),\n",
    "    (\"Guns N' Roses\", \"Rock\", \"Hard Rock\"),\n",
    "    (\"Van Halen\", \"Rock\", \"Hard Rock\"),\n",
    "    (\"Def Leppard\", \"Rock\", \"Hard Rock\"),\n",
    "    (\"Kiss\", \"Rock\", \"Hard Rock\"),\n",
    "    (\"Bon Jovi\", \"Rock\", \"Hard Rock\"),\n",
    "    (\"Whitesnake\", \"Rock\", \"Hard Rock\"),\n",
    "    (\"Scorpions\", \"Rock\", \"Hard Rock\"),\n",
    "    (\"Motörhead\", \"Rock\", \"Hard Rock\"),\n",
    "    (\"Black Sabbath\", \"Metal\", \"Heavy Metal\"),\n",
    "    (\"Iron Maiden\", \"Metal\", \"Heavy Metal\"),\n",
    "    (\"Judas Priest\", \"Metal\", \"Heavy Metal\"),\n",
    "    (\"Metallica\", \"Metal\", \"Heavy Metal\"),\n",
    "    (\"Megadeth\", \"Metal\", \"Heavy Metal\"),\n",
    "    (\"Slayer\", \"Metal\", \"Heavy Metal\"),\n",
    "    (\"Anthrax\", \"Metal\", \"Heavy Metal\"),\n",
    "    (\"Pantera\", \"Metal\", \"Heavy Metal\"),\n",
    "    (\"Dio\", \"Metal\", \"Heavy Metal\"),\n",
    "    (\"Saxon\", \"Metal\", \"Heavy Metal\"),\n",
    "    (\"Metallica\", \"Metal\", \"Thrash Metal\"),\n",
    "    (\"Megadeth\", \"Metal\", \"Thrash Metal\"),\n",
    "    (\"Slayer\", \"Metal\", \"Thrash Metal\"),\n",
    "    (\"Anthrax\", \"Metal\", \"Thrash Metal\"),\n",
    "    (\"Exodus\", \"Metal\", \"Thrash Metal\"),\n",
    "    (\"Overkill\", \"Metal\", \"Thrash Metal\"),\n",
    "    (\"Testament\", \"Metal\", \"Thrash Metal\"),\n",
    "    (\"Kreator\", \"Metal\", \"Thrash Metal\"),\n",
    "    (\"Sepultura\", \"Metal\", \"Thrash Metal\"),\n",
    "    (\"Sodom\", \"Metal\", \"Thrash Metal\"),\n",
    "    (\"Death\", \"Metal\", \"Death Metal\"),\n",
    "    (\"Cannibal Corpse\", \"Metal\", \"Death Metal\"),\n",
    "    (\"Morbid Angel\", \"Metal\", \"Death Metal\"),\n",
    "    (\"Obituary\", \"Metal\", \"Death Metal\"),\n",
    "    (\"Deicide\", \"Metal\", \"Death Metal\"),\n",
    "    (\"Entombed\", \"Metal\", \"Death Metal\"),\n",
    "    (\"Dismember\", \"Metal\", \"Death Metal\"),\n",
    "    (\"Carcass\", \"Metal\", \"Death Metal\"),\n",
    "    (\"Bolt Thrower\", \"Metal\", \"Death Metal\"),\n",
    "    (\"At the Gates\", \"Metal\", \"Death Metal\"),\n",
    "    (\"Venom\", \"Metal\", \"Black Metal\"),\n",
    "    (\"Bathory\", \"Metal\", \"Black Metal\"),\n",
    "    (\"Mayhem\", \"Metal\", \"Black Metal\"),\n",
    "    (\"Darkthrone\", \"Metal\", \"Black Metal\"),\n",
    "    (\"Emperor\", \"Metal\", \"Black Metal\"),\n",
    "    (\"Immortal\", \"Metal\", \"Black Metal\"),\n",
    "    (\"Burzum\", \"Metal\", \"Black Metal\"),\n",
    "    (\"Gorgoroth\", \"Metal\", \"Black Metal\"),\n",
    "    (\"Satyricon\", \"Metal\", \"Black Metal\"),\n",
    "    (\"Watain\", \"Metal\", \"Black Metal\"),\n",
    "    (\"Black Sabbath\", \"Metal\", \"Doom Metal\"),\n",
    "    (\"Candlemass\", \"Metal\", \"Doom Metal\"),\n",
    "    (\"Saint Vitus\", \"Metal\", \"Doom Metal\"),\n",
    "    (\"Trouble\", \"Metal\", \"Doom Metal\"),\n",
    "    (\"Electric Wizard\", \"Metal\", \"Doom Metal\"),\n",
    "    (\"My Dying Bride\", \"Metal\", \"Doom Metal\"),\n",
    "    (\"Paradise Lost\", \"Metal\", \"Doom Metal\"),\n",
    "    (\"Pentagram\", \"Metal\", \"Doom Metal\"),\n",
    "    (\"Katatonia\", \"Metal\", \"Doom Metal\"),\n",
    "    (\"Solitude Aeturnus\", \"Metal\", \"Doom Metal\"),\n",
    "    (\"Pink Floyd\", \"Rock\", \"Progressive Rock\"),\n",
    "    (\"King Crimson\", \"Rock\", \"Progressive Rock\"),\n",
    "    (\"Yes\", \"Rock\", \"Progressive Rock\"),\n",
    "    (\"Genesis\", \"Rock\", \"Progressive Rock\"),\n",
    "    (\"Rush\", \"Rock\", \"Progressive Rock\"),\n",
    "    (\"Emerson, Lake & Palmer\", \"Rock\", \"Progressive Rock\"),\n",
    "    (\"Jethro Tull\", \"Rock\", \"Progressive Rock\"),\n",
    "    (\"Camel\", \"Rock\", \"Progressive Rock\"),\n",
    "    (\"Gentle Giant\", \"Rock\", \"Progressive Rock\"),\n",
    "    (\"Van der Graaf Generator\", \"Rock\", \"Progressive Rock\"),\n",
    "    (\"Dream Theater\", \"Metal\", \"Progressive Metal\"),\n",
    "    (\"Opeth\", \"Metal\", \"Progressive Metal\"),\n",
    "    (\"Queensrÿche\", \"Metal\", \"Progressive Metal\"),\n",
    "    (\"Symphony X\", \"Metal\", \"Progressive Metal\"),\n",
    "    (\"Tool\", \"Metal\", \"Progressive Metal\"),\n",
    "    (\"Fates Warning\", \"Metal\", \"Progressive Metal\"),\n",
    "    (\"Pain of Salvation\", \"Metal\", \"Progressive Metal\"),\n",
    "    (\"Porcupine Tree\", \"Metal\", \"Progressive Metal\"),\n",
    "    (\"Between the Buried and Me\", \"Metal\", \"Progressive Metal\"),\n",
    "    (\"Haken\", \"Metal\", \"Progressive Metal\"),\n",
    "    (\"Nirvana\", \"Rock\", \"Alternative Rock\"),\n",
    "    (\"Pearl Jam\", \"Rock\", \"Alternative Rock\"),\n",
    "    (\"Radiohead\", \"Rock\", \"Alternative Rock\"),\n",
    "    (\"Soundgarden\", \"Rock\", \"Alternative Rock\"),\n",
    "    (\"R.E.M.\", \"Rock\", \"Alternative Rock\"),\n",
    "    (\"Alice in Chains\", \"Rock\", \"Alternative Rock\"),\n",
    "    (\"Smashing Pumpkins\", \"Rock\", \"Alternative Rock\"),\n",
    "    (\"Red Hot Chili Peppers\", \"Rock\", \"Alternative Rock\"),\n",
    "    (\"Foo Fighters\", \"Rock\", \"Alternative Rock\"),\n",
    "    (\"Stone Temple Pilots\", \"Rock\", \"Alternative Rock\"),\n",
    "    (\"Nirvana\", \"Rock\", \"Grunge\"),\n",
    "    (\"Pearl Jam\", \"Rock\", \"Grunge\"),\n",
    "    (\"Soundgarden\", \"Rock\", \"Grunge\"),\n",
    "    (\"Alice in Chains\", \"Rock\", \"Grunge\"),\n",
    "    (\"Stone Temple Pilots\", \"Rock\", \"Grunge\"),\n",
    "    (\"Mudhoney\", \"Rock\", \"Grunge\"),\n",
    "    (\"Screaming Trees\", \"Rock\", \"Grunge\"),\n",
    "    (\"Temple of the Dog\", \"Rock\", \"Grunge\"),\n",
    "    (\"Mother Love Bone\", \"Rock\", \"Grunge\"),\n",
    "    (\"Silverchair\", \"Rock\", \"Grunge\"),\n",
    "    (\"The Ramones\", \"Rock\", \"Punk Rock\"),\n",
    "    (\"Sex Pistols\", \"Rock\", \"Punk Rock\"),\n",
    "    (\"The Clash\", \"Rock\", \"Punk Rock\"),\n",
    "    (\"Dead Kennedys\", \"Rock\", \"Punk Rock\"),\n",
    "    (\"The Misfits\", \"Rock\", \"Punk Rock\"),\n",
    "    (\"Bad Religion\", \"Rock\", \"Punk Rock\"),\n",
    "    (\"Black Flag\", \"Rock\", \"Punk Rock\"),\n",
    "    (\"The Offspring\", \"Rock\", \"Punk Rock\"),\n",
    "    (\"Green Day\", \"Rock\", \"Punk Rock\"),\n",
    "    (\"NOFX\", \"Rock\", \"Punk Rock\"),\n",
    "    (\"Joy Division\", \"Rock\", \"Post-Punk\"),\n",
    "    (\"The Cure\", \"Rock\", \"Post-Punk\"),\n",
    "    (\"Siouxsie and the Banshees\", \"Rock\", \"Post-Punk\"),\n",
    "    (\"Bauhaus\", \"Rock\", \"Post-Punk\"),\n",
    "    (\"Echo & the Bunnymen\", \"Rock\", \"Post-Punk\"),\n",
    "    (\"Gang of Four\", \"Rock\", \"Post-Punk\"),\n",
    "    (\"The Smiths\", \"Rock\", \"Post-Punk\"),\n",
    "    (\"Public Image Ltd\", \"Rock\", \"Post-Punk\"),\n",
    "    (\"Wire\", \"Rock\", \"Post-Punk\"),\n",
    "    (\"Killing Joke\", \"Rock\", \"Post-Punk\"),\n",
    "    (\"Depeche Mode\", \"Rock\", \"New Wave\"),\n",
    "    (\"The Police\", \"Rock\", \"New Wave\"),\n",
    "    (\"Duran Duran\", \"Rock\", \"New Wave\"),\n",
    "    (\"Talking Heads\", \"Rock\", \"New Wave\"),\n",
    "    (\"Blondie\", \"Rock\", \"New Wave\"),\n",
    "    (\"The Cars\", \"Rock\", \"New Wave\"),\n",
    "    (\"INXS\", \"Rock\", \"New Wave\"),\n",
    "    (\"Tears for Fears\", \"Rock\", \"New Wave\"),\n",
    "    (\"A Flock of Seagulls\", \"Rock\", \"New Wave\"),\n",
    "    (\"The B-52's\", \"Rock\", \"New Wave\"),\n",
    "    (\"Mötley Crüe\", \"Metal\", \"Glam Metal\"),\n",
    "    (\"Poison\", \"Metal\", \"Glam Metal\"),\n",
    "    (\"Twisted Sister\", \"Metal\", \"Glam Metal\"),\n",
    "    (\"Ratt\", \"Metal\", \"Glam Metal\"),\n",
    "    (\"Skid Row\", \"Metal\", \"Glam Metal\"),\n",
    "    (\"W.A.S.P.\", \"Metal\", \"Glam Metal\"),\n",
    "    (\"Cinderella\", \"Metal\", \"Glam Metal\"),\n",
    "    (\"Quiet Riot\", \"Metal\", \"Glam Metal\"),\n",
    "    (\"Great White\", \"Metal\", \"Glam Metal\"),\n",
    "    (\"L.A. Guns\", \"Metal\", \"Glam Metal\"),\n",
    "    (\"Nine Inch Nails\", \"Metal\", \"Industrial Metal\"),\n",
    "    (\"Ministry\", \"Metal\", \"Industrial Metal\"),\n",
    "    (\"Rammstein\", \"Metal\", \"Industrial Metal\"),\n",
    "    (\"Marilyn Manson\", \"Metal\", \"Industrial Metal\"),\n",
    "    (\"Fear Factory\", \"Metal\", \"Industrial Metal\"),\n",
    "    (\"KMFDM\", \"Metal\", \"Industrial Metal\"),\n",
    "    (\"Godflesh\", \"Metal\", \"Industrial Metal\"),\n",
    "    (\"Rob Zombie\", \"Metal\", \"Industrial Metal\"),\n",
    "    (\"Static-X\", \"Metal\", \"Industrial Metal\"),\n",
    "    (\"Strapping Young Lad\", \"Metal\", \"Industrial Metal\"),\n",
    "    (\"Korn\", \"Metal\", \"Nu Metal\"),\n",
    "    (\"Slipknot\", \"Metal\", \"Nu Metal\"),\n",
    "    (\"Limp Bizkit\", \"Metal\", \"Nu Metal\"),\n",
    "    (\"Linkin Park\", \"Metal\", \"Nu Metal\"),\n",
    "    (\"Deftones\", \"Metal\", \"Nu Metal\"),\n",
    "    (\"Disturbed\", \"Metal\", \"Nu Metal\"),\n",
    "    (\"System of a Down\", \"Metal\", \"Nu Metal\"),\n",
    "    (\"Papa Roach\", \"Metal\", \"Nu Metal\"),\n",
    "    (\"Coal Chamber\", \"Metal\", \"Nu Metal\"),\n",
    "    (\"Mudvayne\", \"Metal\", \"Nu Metal\"),\n",
    "    (\"Killswitch Engage\", \"Metal\", \"Metalcore\"),\n",
    "    (\"As I Lay Dying\", \"Metal\", \"Metalcore\"),\n",
    "    (\"All That Remains\", \"Metal\", \"Metalcore\"),\n",
    "    (\"Trivium\", \"Metal\", \"Metalcore\"),\n",
    "    (\"Parkway Drive\", \"Metal\", \"Metalcore\"),\n",
    "    (\"August Burns Red\", \"Metal\", \"Metalcore\"),\n",
    "    (\"Bullet for My Valentine\", \"Metal\", \"Metalcore\"),\n",
    "    (\"Atreyu\", \"Metal\", \"Metalcore\"),\n",
    "    (\"Unearth\", \"Metal\", \"Metalcore\"),\n",
    "    (\"Bring Me the Horizon\", \"Metal\", \"Metalcore\"),\n",
    "    (\"Neurosis\", \"Metal\", \"Post-Metal\"),\n",
    "    (\"Isis\", \"Metal\", \"Post-Metal\"),\n",
    "    (\"Pelican\", \"Metal\", \"Post-Metal\"),\n",
    "    (\"Cult of Luna\", \"Metal\", \"Post-Metal\"),\n",
    "    (\"Russian Circles\", \"Metal\", \"Post-Metal\"),\n",
    "    (\"Mastodon\", \"Metal\", \"Post-Metal\"),\n",
    "    (\"The Ocean\", \"Metal\", \"Post-Metal\"),\n",
    "    (\"Rosetta\", \"Metal\", \"Post-Metal\"),\n",
    "    (\"Alcest\", \"Metal\", \"Post-Metal\"),\n",
    "    (\"Amenra\", \"Metal\", \"Post-Metal\"),\n",
    "    (\"Kyuss\", \"Rock\", \"Stoner Rock\"),\n",
    "    (\"Queens of the Stone Age\", \"Rock\", \"Stoner Rock\"),\n",
    "    (\"Sleep\", \"Rock\", \"Stoner Rock\"),\n",
    "    (\"Fu Manchu\", \"Rock\", \"Stoner Rock\"),\n",
    "    (\"Monster Magnet\", \"Rock\", \"Stoner Rock\"),\n",
    "    (\"Electric Wizard\", \"Rock\", \"Stoner Rock\"),\n",
    "    (\"Clutch\", \"Rock\", \"Stoner Rock\"),\n",
    "    (\"The Sword\", \"Rock\", \"Stoner Rock\"),\n",
    "    (\"Orange Goblin\", \"Rock\", \"Stoner Rock\"),\n",
    "    (\"Truckfighters\", \"Rock\", \"Stoner Rock\"),\n",
    "    (\"Melvins\", \"Metal\", \"Sludge Metal\"),\n",
    "    (\"Eyehategod\", \"Metal\", \"Sludge Metal\"),\n",
    "    (\"Crowbar\", \"Metal\", \"Sludge Metal\"),\n",
    "    (\"Acid Bath\", \"Metal\", \"Sludge Metal\"),\n",
    "    (\"Down\", \"Metal\", \"Sludge Metal\"),\n",
    "    (\"Corrosion of Conformity\", \"Metal\", \"Sludge Metal\"),\n",
    "    (\"Neurosis\", \"Metal\", \"Sludge Metal\"),\n",
    "    (\"High on Fire\", \"Metal\", \"Sludge Metal\"),\n",
    "    (\"Baroness\", \"Metal\", \"Sludge Metal\"),\n",
    "    (\"Kylesa\", \"Metal\", \"Sludge Metal\"),\n",
    "    (\"Pantera\", \"Metal\", \"Groove Metal\"),\n",
    "    (\"Lamb of God\", \"Metal\", \"Groove Metal\"),\n",
    "    (\"Machine Head\", \"Metal\", \"Groove Metal\"),\n",
    "    (\"Sepultura\", \"Metal\", \"Groove Metal\"),\n",
    "    (\"Fear Factory\", \"Metal\", \"Groove Metal\"),\n",
    "    (\"White Zombie\", \"Metal\", \"Groove Metal\"),\n",
    "    (\"DevilDriver\", \"Metal\", \"Groove Metal\"),\n",
    "    (\"Gojira\", \"Metal\", \"Groove Metal\"),\n",
    "    (\"Soulfly\", \"Metal\", \"Groove Metal\"),\n",
    "    (\"Chimaira\", \"Metal\", \"Groove Metal\"),\n",
    "    (\"Finntroll\", \"Metal\", \"Folk Metal\"),\n",
    "    (\"Ensiferum\", \"Metal\", \"Folk Metal\"),\n",
    "    (\"Eluveitie\", \"Metal\", \"Folk Metal\"),\n",
    "    (\"Korpiklaani\", \"Metal\", \"Folk Metal\"),\n",
    "    (\"Turisas\", \"Metal\", \"Folk Metal\"),\n",
    "    (\"Alestorm\", \"Metal\", \"Folk Metal\"),\n",
    "    (\"Moonsorrow\", \"Metal\", \"Folk Metal\"),\n",
    "    (\"Skyclad\", \"Metal\", \"Folk Metal\"),\n",
    "    (\"Týr\", \"Metal\", \"Folk Metal\"),\n",
    "    (\"Wintersun\", \"Metal\", \"Folk Metal\"),\n",
    "    (\"Type O Negative\", \"Metal\", \"Gothic Metal\"),\n",
    "    (\"Paradise Lost\", \"Metal\", \"Gothic Metal\"),\n",
    "    (\"My Dying Bride\", \"Metal\", \"Gothic Metal\"),\n",
    "    (\"Lacuna Coil\", \"Metal\", \"Gothic Metal\"),\n",
    "    (\"Within Temptation\", \"Metal\", \"Gothic Metal\"),\n",
    "    (\"Theatre of Tragedy\", \"Metal\", \"Gothic Metal\"),\n",
    "    (\"Moonspell\", \"Metal\", \"Gothic Metal\"),\n",
    "    (\"Tristania\", \"Metal\", \"Gothic Metal\"),\n",
    "    (\"Leaves' Eyes\", \"Metal\", \"Gothic Metal\"),\n",
    "    (\"Draconian\", \"Metal\", \"Gothic Metal\"),\n",
    "    (\"Nightwish\", \"Metal\", \"Symphonic Metal\"),\n",
    "    (\"Epica\", \"Metal\", \"Symphonic Metal\"),\n",
    "    (\"Within Temptation\", \"Metal\", \"Symphonic Metal\"),\n",
    "    (\"Therion\", \"Metal\", \"Symphonic Metal\"),\n",
    "    (\"Kamelot\", \"Metal\", \"Symphonic Metal\"),\n",
    "    (\"Rhapsody of Fire\", \"Metal\", \"Symphonic Metal\"),\n",
    "    (\"Delain\", \"Metal\", \"Symphonic Metal\"),\n",
    "    (\"Leaves' Eyes\", \"Metal\", \"Symphonic Metal\"),\n",
    "    (\"Xandria\", \"Metal\", \"Symphonic Metal\"),\n",
    "    (\"After Forever\", \"Metal\", \"Symphonic Metal\")\n",
    "]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(bands_data, columns=[\"Band\", \"Genre\", \"Subgenre\"])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "bands = [\n",
    "    \"The Beatles\", \"The Rolling Stones\", \"The Who\", \"Led Zeppelin\", \"The Doors\",\n",
    "    \"Pink Floyd\", \"Queen\", \"Creedence Clearwater Revival\", \"Jimi Hendrix\", \"Deep Purple\",\n",
    "    \"AC/DC\", \"Aerosmith\", \"Guns N' Roses\", \"Van Halen\", \"Def Leppard\",\n",
    "    \"Kiss\", \"Bon Jovi\", \"Whitesnake\", \"Scorpions\", \"Motörhead\",\n",
    "    \"Black Sabbath\", \"Iron Maiden\", \"Judas Priest\", \"Metallica\", \"Megadeth\",\n",
    "    \"Slayer\", \"Anthrax\", \"Pantera\", \"Dio\", \"Saxon\",\n",
    "    \"Death\", \"Cannibal Corpse\", \"Morbid Angel\", \"Obituary\", \"Deicide\",\n",
    "    \"Entombed\", \"Dismember\", \"Carcass\", \"Bolt Thrower\", \"At the Gates\",\n",
    "    \"Venom\", \"Bathory\", \"Mayhem\", \"Darkthrone\", \"Emperor\",\n",
    "    \"Immortal\", \"Burzum\", \"Gorgoroth\", \"Satyricon\", \"Watain\",\n",
    "    \"Candlemass\", \"Saint Vitus\", \"Trouble\", \"Electric Wizard\",\n",
    "    \"My Dying Bride\", \"Paradise Lost\", \"Pentagram\", \"Katatonia\", \"Solitude Aeturnus\",\n",
    "    \"King Crimson\", \"Yes\", \"Genesis\", \"Rush\",\n",
    "    \"Emerson, Lake & Palmer\", \"Jethro Tull\", \"Camel\", \"Gentle Giant\", \"Van der Graaf Generator\",\n",
    "    \"Dream Theater\", \"Opeth\", \"Queensrÿche\", \"Symphony X\", \"Tool\",\n",
    "    \"Fates Warning\", \"Pain of Salvation\", \"Porcupine Tree\", \"Between the Buried and Me\", \"Haken\",\n",
    "    \"Nirvana\", \"Pearl Jam\", \"Radiohead\", \"Soundgarden\", \"R.E.M.\",\n",
    "    \"Alice in Chains\", \"Smashing Pumpkins\", \"Red Hot Chili Peppers\", \"Foo Fighters\", \"Stone Temple Pilots\",\n",
    "    \"Mudhoney\", \"Screaming Trees\", \"Temple of the Dog\", \"Mother Love Bone\", \"Silverchair\",\n",
    "    \"The Ramones\", \"Sex Pistols\", \"The Clash\", \"Dead Kennedys\", \"The Misfits\",\n",
    "    \"Bad Religion\", \"Black Flag\", \"The Offspring\", \"Green Day\", \"NOFX\",\n",
    "    \"Joy Division\", \"The Cure\", \"Siouxsie and the Banshees\", \"Bauhaus\", \"Echo & the Bunnymen\",\n",
    "    \"Gang of Four\", \"The Smiths\", \"Public Image Ltd\", \"Wire\", \"Killing Joke\",\n",
    "    \"Depeche Mode\", \"The Police\", \"Duran Duran\", \"Talking Heads\", \"Blondie\",\n",
    "    \"The Cars\", \"INXS\", \"Tears for Fears\", \"A Flock of Seagulls\", \"The B-52's\",\n",
    "    \"Mötley Crüe\", \"Poison\", \"Twisted Sister\", \"Ratt\", \"Skid Row\",\n",
    "    \"W.A.S.P.\", \"Cinderella\", \"Quiet Riot\", \"Great White\", \"L.A. Guns\",\n",
    "    \"Nine Inch Nails\", \"Ministry\", \"Rammstein\", \"Marilyn Manson\", \"Fear Factory\",\n",
    "    \"KMFDM\", \"Godflesh\", \"Rob Zombie\", \"Static-X\", \"Strapping Young Lad\",\n",
    "    \"Korn\", \"Slipknot\", \"Limp Bizkit\", \"Linkin Park\", \"Deftones\",\n",
    "    \"Disturbed\", \"System of a Down\", \"Papa Roach\", \"Coal Chamber\", \"Mudvayne\",\n",
    "    \"Killswitch Engage\", \"As I Lay Dying\", \"All That Remains\", \"Trivium\", \"Parkway Drive\",\n",
    "    \"August Burns Red\", \"Bullet for My Valentine\", \"Atreyu\", \"Unearth\", \"Bring Me the Horizon\",\n",
    "    \"Neurosis\", \"Isis\", \"Pelican\", \"Cult of Luna\", \"Russian Circles\",\n",
    "    \"Mastodon\", \"The Ocean\", \"Rosetta\", \"Alcest\", \"Amenra\",\n",
    "    \"Kyuss\", \"Queens of the Stone Age\", \"Sleep\", \"Fu Manchu\", \"Monster Magnet\",\n",
    "    \"Electric Wizard\", \"Clutch\", \"The Sword\", \"Orange Goblin\", \"Truckfighters\",\n",
    "    \"Melvins\", \"Eyehategod\", \"Crowbar\", \"Acid Bath\", \"Down\",\n",
    "    \"Corrosion of Conformity\", \"High on Fire\", \"Baroness\", \"Kylesa\",\n",
    "    \"Lamb of God\", \"Machine Head\", \"Sepultura\",\n",
    "    \"White Zombie\", \"DevilDriver\", \"Gojira\", \"Soulfly\", \"Chimaira\",\n",
    "    \"Finntroll\", \"Ensiferum\", \"Eluveitie\", \"Korpiklaani\", \"Turisas\",\n",
    "    \"Alestorm\", \"Moonsorrow\", \"Skyclad\", \"Týr\", \"Wintersun\",\n",
    "    \"Type O Negative\", \"Leaves' Eyes\", \"Draconian\",\n",
    "    \"Nightwish\", \"Epica\", \"Therion\", \"Kamelot\",\n",
    "    \"Rhapsody of Fire\", \"Delain\", \"Xandria\", \"After Forever\"\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Constants\n",
    "BASE_URL = 'http://www.azlyrics.com'\n",
    "SAVE_DIR = 'lyrics'\n",
    "\n",
    "# List of artists to search for\n",
    "ARTISTS = bands  # Example list of artists\n",
    "\n",
    "# Function to convert artist name to URL-friendly format\n",
    "def format_artist_name(artist):\n",
    "    if artist == \"Guns N' Roses\":\n",
    "        return \"guns\"\n",
    "    elif artist == \"Motörhead\":\n",
    "        return \"motorhead\"\n",
    "    else:\n",
    "        return artist.lower().replace(\"the\", \"\").replace(' ', '').replace(\"'\", \"\").replace(\"ý\", \"\")\n",
    "\n",
    "# Function to get the URL for an artist page\n",
    "def get_artist_url(artist):\n",
    "    formatted_name = format_artist_name(artist)\n",
    "    first_letter = formatted_name[0]\n",
    "    return f\"{BASE_URL}/{first_letter}/{formatted_name}.html\"\n",
    "\n",
    "# Function to scrape song links from an artist page\n",
    "def get_song_links(artist_url):\n",
    "    print(f\"Fetching song links from {artist_url}\")\n",
    "    response = requests.get(artist_url)\n",
    "    if(response):\n",
    "        print(\"Fetched\")\n",
    "    else:\n",
    "        print(\"Failed\")\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    song_links = []\n",
    "    divs = soup.find_all('div', class_='listalbum-item')\n",
    "    for div in divs:\n",
    "        for a in div.find_all('a', href=True):\n",
    "            song_links.append(BASE_URL + a['href'])  # Fix relative URL\n",
    "    print(song_links)\n",
    "    return song_links\n",
    "\n",
    "# Function to scrape lyrics and song title from a song page\n",
    "def get_lyrics(song_url):\n",
    "    print(f\"Fetching lyrics from {song_url}\")\n",
    "    response = requests.get(song_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    lyrics_div = soup.find('div', class_=None, id=None)\n",
    "\n",
    "    if lyrics_div:\n",
    "        lyrics = lyrics_div.get_text(strip=True, separator='\\n')\n",
    "        all_b_elements = soup.find_all('b')\n",
    "        if len(all_b_elements) >= 2:\n",
    "            song_title = all_b_elements[1].text.strip()\n",
    "        else:\n",
    "            song_title = None  # Extract song title from the page\n",
    "        print(\"Fetched\")\n",
    "        return song_title, lyrics\n",
    "    print(\"Failed\")\n",
    "    return None, None\n",
    "\n",
    "# Main script\n",
    "data = []  # List to store the collected data\n",
    "song_fetch_failed = False  # Flag to track if any song fetching has failed\n",
    "\n",
    "for artist in ARTISTS:\n",
    "    artist_url = get_artist_url(artist)\n",
    "\n",
    "    try:\n",
    "        # Fetch song links for each artist\n",
    "        song_links = get_song_links(artist_url)\n",
    "\n",
    "        for song_link in song_links:\n",
    "            # Fetch lyrics and song title for each song\n",
    "            song_title, lyrics = get_lyrics(song_link)\n",
    "\n",
    "            if lyrics:\n",
    "                # Extract band, genre, and subgenre from the original dataset\n",
    "                band_genre_subgenre = df[df['Band'] == artist]\n",
    "                genre = band_genre_subgenre['Genre'].iloc[0]\n",
    "                subgenre = band_genre_subgenre['Subgenre'].iloc[0]\n",
    "\n",
    "                # Append collected data to the list\n",
    "                data.append({\n",
    "                    'Band': artist,\n",
    "                    'Genre': genre,\n",
    "                    'Subgenre': subgenre,\n",
    "                    'Song Title': song_title,\n",
    "                    'Lyrics': lyrics\n",
    "                })\n",
    "                print(f'Saved lyrics for {song_title} by {artist}')\n",
    "            else:\n",
    "                print(f'Failed to fetch lyrics for {song_link}')\n",
    "                song_fetch_failed = True\n",
    "                break  # Stop processing further songs for this artist\n",
    "\n",
    "            # Be polite to the server\n",
    "            random_number = random.randint(10, 20)\n",
    "            time.sleep(random_number)\n",
    "\n",
    "        if song_fetch_failed:\n",
    "            break  # Stop processing further artists if a song fetching has failed\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process artist {artist}: {e}\")\n",
    "\n",
    "# Convert the collected data into a pandas DataFrame\n",
    "lyrics_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(lyrics_df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "lyrics_df.to_csv('lyrics_dataset.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Your Genius API access token\n",
    "access_token = 'G0AyWjEdB67AFEr9byFlU3bRZMATSHseZFz1mezUllAFVs89AIhQCv8g95HNZhUS'\n",
    "\n",
    "# Function to search for a song on Genius\n",
    "def search_song(song_title, artist_name):\n",
    "    base_url = \"https://api.genius.com\"\n",
    "    headers = {'Authorization': 'Bearer ' + access_token}\n",
    "    search_url = base_url + \"/search\"\n",
    "    data = {'q': song_title + ' ' + artist_name}\n",
    "    response = requests.get(search_url, headers=headers, params=data)\n",
    "    return response.json()\n",
    "\n",
    "# Function to get song URL from the search results\n",
    "def get_song_url(search_results, artist_name):\n",
    "    for hit in search_results['response']['hits']:\n",
    "        if hit['result']['primary_artist']['name'].lower() == artist_name.lower():\n",
    "            return hit['result']['url']\n",
    "    return None\n",
    "\n",
    "# Function to scrape song lyrics from Genius\n",
    "def scrape_lyrics(song_url):\n",
    "    page = requests.get(song_url)\n",
    "    html = BeautifulSoup(page.text, 'html.parser')\n",
    "    divs = html.find_all('div', class_='Lyrics__Container-sc-1ynbvzw-1 kUgSbL')\n",
    "    lyrics = \"\"\n",
    "    for div in divs:\n",
    "        lyrics += div.get_text(strip=False)  # Extract and clean the text\n",
    "    return lyrics\n",
    "\n",
    "data = []\n",
    "# Loop through each artist\n",
    "for artist_name in bands:\n",
    "    print(f\"Songs by {artist_name}:\")\n",
    "    # Search for the artist's songs\n",
    "    search_results = search_song('', artist_name)\n",
    "\n",
    "    # Loop through the search results to get song URLs and lyrics\n",
    "    for hit in search_results['response']['hits']:\n",
    "        song_title = hit['result']['title']\n",
    "        song_url = hit['result']['url']\n",
    "        # Scrape the lyrics\n",
    "        lyrics = scrape_lyrics(song_url)\n",
    "        if lyrics:\n",
    "                # Extract band, genre, and subgenre from the original dataset\n",
    "                band_genre_subgenre = df[df['Band'] == artist_name]\n",
    "                genre = band_genre_subgenre['Genre'].iloc[0]\n",
    "                subgenre = band_genre_subgenre['Subgenre'].iloc[0]\n",
    "\n",
    "                # Append collected data to the list\n",
    "                data.append({\n",
    "                    'Band': artist_name,\n",
    "                    'Genre': genre,\n",
    "                    'Subgenre': subgenre,\n",
    "                    'Song Title': song_title,\n",
    "                    'Lyrics': lyrics\n",
    "                })\n",
    "                print(f'Saved lyrics for {song_title} by {artist_name}')\n",
    "        else:\n",
    "            print(f'Failed to fetch lyrics for {song_title}')\n",
    "            song_fetch_failed = True\n",
    "            break  # Stop processing further songs for this artist\n",
    "lyrics_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(lyrics_df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "lyrics_df.to_csv('lyrics_dataset.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bands' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 35\u001B[0m\n\u001B[0;32m     33\u001B[0m data \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     34\u001B[0m \u001B[38;5;66;03m# Loop through each artist\u001B[39;00m\n\u001B[1;32m---> 35\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m artist_name \u001B[38;5;129;01min\u001B[39;00m bands:\n\u001B[0;32m     36\u001B[0m    \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSongs by \u001B[39m\u001B[38;5;132;01m{\u001B[39;00martist_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     37\u001B[0m    \u001B[38;5;66;03m# Search for the artist's songs\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'bands' is not defined"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def insert_newline_csv(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8', errors='ignore') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        rows = list(reader)\n",
    "\n",
    "    modified_rows = []\n",
    "    for row in rows:\n",
    "        modified_row = []\n",
    "        for item in row:\n",
    "            modified_item = \"\"\n",
    "            i = 0\n",
    "            while i < len(item) - 1:\n",
    "                if item[i].islower() and item[i + 1].isupper():\n",
    "                    modified_item += item[i] + ' '\n",
    "                else:\n",
    "                    modified_item += item[i]\n",
    "                i += 1\n",
    "            modified_item += item[-1]\n",
    "            modified_row.append(modified_item)\n",
    "        modified_rows.append(modified_row)\n",
    "\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerows(modified_rows)\n",
    "\n",
    "import csv\n",
    "import re\n",
    "\n",
    "def remove_square_brackets_csv(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8', errors='ignore') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        rows = list(reader)\n",
    "\n",
    "    modified_rows = []\n",
    "    for row in rows:\n",
    "        modified_row = []\n",
    "        for item in row:\n",
    "            # Use regular expression to remove content between square brackets\n",
    "            modified_item = re.sub(r'\\[.*?\\]', '', item)\n",
    "            modified_row.append(modified_item)\n",
    "        modified_rows.append(modified_row)\n",
    "\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerows(modified_rows)\n",
    "\n",
    "input_file = \"input.csv\"  # Replace with your input file path\n",
    "output_file = \"output.csv\"  # Replace with your output file path\n",
    "remove_square_brackets_csv(input_file, output_file)\n",
    "\n",
    "\n",
    "input_file = \"output.csv\"  # Replace with your input file path\n",
    "output_file = \"dataset.csv\"  # Replace with your output file path\n",
    "remove_square_brackets_csv(input_file, output_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 20.7 GiB for an array with shape (612894, 9058) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[45], line 33\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m# Pad sequences\u001B[39;00m\n\u001B[0;32m     32\u001B[0m max_sequence_len \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m([\u001B[38;5;28mlen\u001B[39m(x) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m input_sequences])\n\u001B[1;32m---> 33\u001B[0m input_sequences \u001B[38;5;241m=\u001B[39m pad_sequences(input_sequences, maxlen\u001B[38;5;241m=\u001B[39mmax_sequence_len, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpre\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     35\u001B[0m \u001B[38;5;66;03m# Create predictors and label\u001B[39;00m\n\u001B[0;32m     36\u001B[0m X, y \u001B[38;5;241m=\u001B[39m input_sequences[:,:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], input_sequences[:,\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\IIoTCA\\Lib\\site-packages\\keras\\src\\utils\\sequence_utils.py:113\u001B[0m, in \u001B[0;36mpad_sequences\u001B[1;34m(sequences, maxlen, dtype, padding, truncating, value)\u001B[0m\n\u001B[0;32m    106\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m dtype \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mobject\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_dtype_str:\n\u001B[0;32m    107\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    108\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`dtype` \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdtype\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not compatible with `value`\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms type: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    109\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(value)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mYou should set `dtype=object` for variable length \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    110\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrings.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    111\u001B[0m     )\n\u001B[1;32m--> 113\u001B[0m x \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mfull((num_samples, maxlen) \u001B[38;5;241m+\u001B[39m sample_shape, value, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx, s \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(sequences):\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(s):\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\IIoTCA\\Lib\\site-packages\\numpy\\core\\numeric.py:329\u001B[0m, in \u001B[0;36mfull\u001B[1;34m(shape, fill_value, dtype, order, like)\u001B[0m\n\u001B[0;32m    327\u001B[0m     fill_value \u001B[38;5;241m=\u001B[39m asarray(fill_value)\n\u001B[0;32m    328\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m fill_value\u001B[38;5;241m.\u001B[39mdtype\n\u001B[1;32m--> 329\u001B[0m a \u001B[38;5;241m=\u001B[39m empty(shape, dtype, order)\n\u001B[0;32m    330\u001B[0m multiarray\u001B[38;5;241m.\u001B[39mcopyto(a, fill_value, casting\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124munsafe\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m a\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 20.7 GiB for an array with shape (612894, 9058) and data type int32"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Concatenate band name, genre, and subgenre with the lyrics\n",
    "df['Input'] = df['Band'] + ' <genre> ' + df['Genre'] + ' <subgenre> ' + df['Subgenre'] + ' <lyrics> ' + df['Lyrics']\n",
    "\n",
    "# Tokenizer and padding functions\n",
    "class CustomTokenizer:\n",
    "    def __init__(self, num_words=None):\n",
    "        self.word_index = {}\n",
    "        self.index_word = {}\n",
    "        self.vocab_size = 0\n",
    "        self.num_words = num_words\n",
    "\n",
    "    def fit_on_texts(self, texts):\n",
    "        words = [word for text in texts for word in word_tokenize(text.lower())]\n",
    "        freq_dist = FreqDist(words)\n",
    "        if self.num_words:\n",
    "            freq_dist = dict(freq_dist.most_common(self.num_words))\n",
    "        self.word_index = {word: index + 1 for index, (word, _) in enumerate(freq_dist.items())}\n",
    "        self.index_word = {index: word for word, index in self.word_index.items()}\n",
    "        self.vocab_size = len(self.word_index) + 1\n",
    "\n",
    "    def texts_to_sequences(self, texts):\n",
    "        return [[self.word_index[word] for word in word_tokenize(text.lower()) if word in self.word_index] for text in texts]\n",
    "\n",
    "def pad_sequences(sequences, maxlen, padding='pre'):\n",
    "    padded_sequences = np.zeros((len(sequences), maxlen), dtype=np.int32)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        if padding == 'pre':\n",
    "            padded_sequences[i, -len(seq):] = np.array(seq)[:maxlen]\n",
    "        elif padding == 'post':\n",
    "            padded_sequences[i, :len(seq)] = np.array(seq)[:maxlen]\n",
    "    return padded_sequences\n",
    "\n",
    "# Tokenize the input data\n",
    "max_vocab_size = 5000  # Limit the vocabulary size\n",
    "tokenizer = CustomTokenizer(num_words=max_vocab_size)\n",
    "tokenizer.fit_on_texts(df['Input'])\n",
    "total_words = tokenizer.vocab_size\n",
    "\n",
    "input_sequences = []\n",
    "for line in df['Input']:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# Pad sequences\n",
    "max_sequence_len = 100  # Limit the maximum sequence length\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n",
    "\n",
    "# Create predictors and label\n",
    "X, y = input_sequences[:,:-1], input_sequences[:,-1]\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.long)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "dataset = LyricsDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define the model\n",
    "class LyricsModel(nn.Module):\n",
    "    def __init__(self, total_words, embed_size, hidden_size, max_sequence_len):\n",
    "        super(LyricsModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(total_words, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, total_words)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "embed_size = 100\n",
    "hidden_size = 150\n",
    "\n",
    "model = LyricsModel(total_words, embed_size, hidden_size, max_sequence_len).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 100\n",
    "best_loss = float('inf')\n",
    "best_model_path = 'best_lyrics_model.pth'\n",
    "\n",
    "import pickle\n",
    "with open('tokenizer.pkl', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    progress_bar = tqdm(dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)\n",
    "    for inputs, labels in progress_bar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / len(dataloader)\n",
    "    if avg_epoch_loss < best_loss:\n",
    "        best_loss = avg_epoch_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_epoch_loss:.4f} (Best Model Saved)\")\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_epoch_loss:.4f}')\n",
    "\n",
    "# Generating lyrics\n",
    "def generate_lyrics(seed_text, next_words, model, max_sequence_len, tokenizer):\n",
    "    model.eval()\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        token_list = torch.tensor(token_list).long().to(device)\n",
    "        with torch.no_grad():\n",
    "            predicted = model(token_list)\n",
    "            predicted_index = torch.argmax(predicted, dim=1).item()\n",
    "        output_word = tokenizer.index_word.get(predicted_index, \"\")\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text\n",
    "\n",
    "# Loading the best model\n",
    "best_model = LyricsModel(total_words, embed_size, hidden_size, max_sequence_len).to(device)\n",
    "best_model.load_state_dict(torch.load(best_model_path))\n",
    "best_model.eval()\n",
    "\n",
    "# Generate lyrics using the best model\n",
    "seed_text = \"Metallica\"\n",
    "generated_lyrics = generate_lyrics(seed_text, 100, best_model, max_sequence_len, tokenizer)\n",
    "print(generated_lyrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Loading the best model and tokenizer\n",
    "best_model_path = 'best_lyrics_model.pth'\n",
    "tokenizer_path = 'tokenizer.pkl'\n",
    "\n",
    "# Assuming 'tokenizer' is the instance of CustomTokenizer\n",
    "with open(tokenizer_path, 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "total_words = tokenizer.vocab_size\n",
    "embed_size = 100\n",
    "hidden_size = 150\n",
    "max_sequence_len = 100\n",
    "\n",
    "best_model = LyricsModel(total_words, embed_size, hidden_size, max_sequence_len).to(device)\n",
    "best_model.load_state_dict(torch.load(best_model_path))\n",
    "best_model.eval()\n",
    "\n",
    "# Generate lyrics using the best model\n",
    "seed_text = \"Tyr <genre> Metal\"\n",
    "generated_lyrics = generate_lyrics(seed_text, 100, best_model, max_sequence_len, tokenizer, temperature=0.8)\n",
    "print(generated_lyrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Encode labels\n",
    "label_encoders = {\n",
    "    'Band': LabelEncoder(),\n",
    "    'Genre': LabelEncoder(),\n",
    "    'Subgenre': LabelEncoder()\n",
    "}\n",
    "df['Band'] = label_encoders['Band'].fit_transform(df['Band'])\n",
    "df['Genre'] = label_encoders['Genre'].fit_transform(df['Genre'])\n",
    "df['Subgenre'] = label_encoders['Subgenre'].fit_transform(df['Subgenre'])\n",
    "\n",
    "# Concatenate band name, genre, and subgenre with the lyrics\n",
    "df['Input'] = df['Band'].astype(str) + ' <genre> ' + df['Genre'].astype(str) + ' <subgenre> ' + df['Subgenre'].astype(str) + ' <lyrics> ' + df['Lyrics']\n",
    "\n",
    "# Tokenizer and padding functions\n",
    "class CustomTokenizer:\n",
    "    def __init__(self, num_words=None):\n",
    "        self.word_index = {}\n",
    "        self.index_word = {}\n",
    "        self.vocab_size = 0\n",
    "        self.num_words = num_words\n",
    "\n",
    "    def fit_on_texts(self, texts):\n",
    "        words = [word for text in texts for word in word_tokenize(text.lower())]\n",
    "        freq_dist = FreqDist(words)\n",
    "        if self.num_words:\n",
    "            freq_dist = dict(freq_dist.most_common(self.num_words))\n",
    "        self.word_index = {word: index + 1 for index, (word, _) in enumerate(freq_dist.items())}\n",
    "        self.index_word = {index: word for word, index in self.word_index.items()}\n",
    "        self.vocab_size = len(self.word_index) + 1\n",
    "\n",
    "    def texts_to_sequences(self, texts):\n",
    "        return [[self.word_index[word] for word in word_tokenize(text.lower()) if word in self.word_index] for text in texts]\n",
    "\n",
    "def pad_sequences(sequences, maxlen, padding='pre'):\n",
    "    padded_sequences = np.zeros((len(sequences), maxlen), dtype=np.int32)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        if padding == 'pre':\n",
    "            padded_sequences[i, -len(seq):] = np.array(seq)[:maxlen]\n",
    "        elif padding == 'post':\n",
    "            padded_sequences[i, :len(seq)] = np.array(seq)[:maxlen]\n",
    "    return padded_sequences\n",
    "\n",
    "# Tokenize the input data\n",
    "max_vocab_size = 5000  # Limit the vocabulary size\n",
    "tokenizer = CustomTokenizer(num_words=max_vocab_size)\n",
    "tokenizer.fit_on_texts(df['Input'])\n",
    "total_words = tokenizer.vocab_size\n",
    "\n",
    "input_sequences = tokenizer.texts_to_sequences(df['Input'])\n",
    "max_sequence_len = 100  # Limit the maximum sequence length\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n",
    "\n",
    "# Create predictors and label\n",
    "X = torch.tensor(input_sequences, dtype=torch.long)\n",
    "y_band = torch.tensor(df['Band'].values, dtype=torch.long)\n",
    "y_genre = torch.tensor(df['Genre'].values, dtype=torch.long)\n",
    "y_subgenre = torch.tensor(df['Subgenre'].values, dtype=torch.long)\n",
    "\n",
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, X, y_band, y_genre, y_subgenre):\n",
    "        self.X = X\n",
    "        self.y_band = y_band\n",
    "        self.y_genre = y_genre\n",
    "        self.y_subgenre = y_subgenre\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y_band[idx], self.y_genre[idx], self.y_subgenre[idx]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "dataset = LyricsDataset(X, y_band, y_genre, y_subgenre)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define the model\n",
    "class LyricsClassificationModel(nn.Module):\n",
    "    def __init__(self, total_words, embed_size, hidden_size, max_sequence_len, num_bands, num_genres, num_subgenres):\n",
    "        super(LyricsClassificationModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(total_words, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
    "        self.fc_band = nn.Linear(hidden_size, num_bands)\n",
    "        self.fc_genre = nn.Linear(hidden_size, num_genres)\n",
    "        self.fc_subgenre = nn.Linear(hidden_size, num_subgenres)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]\n",
    "        band_out = self.fc_band(x)\n",
    "        genre_out = self.fc_genre(x)\n",
    "        subgenre_out = self.fc_subgenre(x)\n",
    "        return band_out, genre_out, subgenre_out\n",
    "\n",
    "embed_size = 100\n",
    "hidden_size = 150\n",
    "num_bands = len(label_encoders['Band'].classes_)\n",
    "num_genres = len(label_encoders['Genre'].classes_)\n",
    "num_subgenres = len(label_encoders['Subgenre'].classes_)\n",
    "\n",
    "model = LyricsClassificationModel(total_words, embed_size, hidden_size, max_sequence_len, num_bands, num_genres, num_subgenres).to(device)\n",
    "criterion_band = nn.CrossEntropyLoss()\n",
    "criterion_genre = nn.CrossEntropyLoss()\n",
    "criterion_subgenre = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 100\n",
    "best_loss = float('inf')\n",
    "best_model_path = 'best_lyrics_classification_model.pth'\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for inputs, labels_band, labels_genre, labels_subgenre in dataloader:\n",
    "        inputs, labels_band, labels_genre, labels_subgenre = inputs.to(device), labels_band.to(device), labels_genre.to(device), labels_subgenre.to(device)\n",
    "        outputs_band, outputs_genre, outputs_subgenre = model(inputs)\n",
    "        loss_band = criterion_band(outputs_band, labels_band)\n",
    "        loss_genre = criterion_genre(outputs_genre, labels_genre)\n",
    "        loss_subgenre = criterion_subgenre(outputs_subgenre, labels_subgenre)\n",
    "\n",
    "        loss = loss_band + loss_genre + loss_subgenre\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / len(dataloader)\n",
    "    if avg_epoch_loss < best_loss:\n",
    "        best_loss = avg_epoch_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_epoch_loss:.4f} (Best Model Saved)\")\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_epoch_loss:.4f}')\n",
    "\n",
    "# After training the model\n",
    "with open('tokenizer_claassif.pkl', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('label_encoders.pkl', 'wb') as handle:\n",
    "    pickle.dump(label_encoders, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Load the best model\n",
    "best_model = LyricsClassificationModel(total_words, embed_size, hidden_size, max_sequence_len, num_bands, num_genres, num_subgenres).to(device)\n",
    "best_model.load_state_dict(torch.load(best_model_path))\n",
    "best_model.eval()\n",
    "\n",
    "# Predict genre, subgenre, and band function\n",
    "def predict_genre_subgenre_band(text, model, max_sequence_len, tokenizer, label_encoders):\n",
    "    model.eval()\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    token_list = torch.tensor(token_list).long().to(device)\n",
    "    with torch.no_grad():\n",
    "        output_band, output_genre, output_subgenre = model(token_list)\n",
    "        predicted_band_idx = torch.argmax(output_band, dim=1).item()\n",
    "        predicted_genre_idx = torch.argmax(output_genre, dim=1).item()\n",
    "        predicted_subgenre_idx = torch.argmax(output_subgenre, dim=1).item()\n",
    "    predicted_band = label_encoders['Band'].inverse_transform([predicted_band_idx])[0]\n",
    "    predicted_genre = label_encoders['Genre'].inverse_transform([predicted_genre_idx])[0]\n",
    "    predicted_subgenre = label_encoders['Subgenre'].inverse_transform([predicted_subgenre_idx])[0]\n",
    "    return predicted_band, predicted_genre, predicted_subgenre"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Embedding.__init__() got an unexpected keyword argument 'input_length'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[44], line 19\u001B[0m\n\u001B[0;32m     16\u001B[0m embed_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m100\u001B[39m\n\u001B[0;32m     17\u001B[0m hidden_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m150\u001B[39m\n\u001B[1;32m---> 19\u001B[0m model \u001B[38;5;241m=\u001B[39m LyricsModel(total_words, embed_size, hidden_size, max_sequence_len)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     20\u001B[0m criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\n\u001B[0;32m     21\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m)\n",
      "Cell \u001B[1;32mIn[44], line 5\u001B[0m, in \u001B[0;36mLyricsModel.__init__\u001B[1;34m(self, total_words, embed_size, hidden_size, max_sequence_len)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, total_words, embed_size, hidden_size, max_sequence_len):\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28msuper\u001B[39m(LyricsModel, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n\u001B[1;32m----> 5\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mEmbedding(total_words, embed_size, input_length\u001B[38;5;241m=\u001B[39mmax_sequence_len\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlstm \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mLSTM(embed_size, hidden_size, batch_first\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mLinear(hidden_size, total_words)\n",
      "\u001B[1;31mTypeError\u001B[0m: Embedding.__init__() got an unexpected keyword argument 'input_length'"
     ]
    }
   ],
   "source": [
    "def load_model_and_encoders(model_path, tokenizer_path, encoders_path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Load the tokenizer\n",
    "    with open(tokenizer_path, 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "\n",
    "    # Load the label encoders\n",
    "    with open(encoders_path, 'rb') as handle:\n",
    "        label_encoders = pickle.load(handle)\n",
    "\n",
    "    # Define the model structure and load the trained weights\n",
    "    total_words = tokenizer.vocab_size\n",
    "    embed_size = 100\n",
    "    hidden_size = 150\n",
    "    num_bands = len(label_encoders['Band'].classes_)\n",
    "    num_genres = len(label_encoders['Genre'].classes_)\n",
    "    num_subgenres = len(label_encoders['Subgenre'].classes_)\n",
    "    max_sequence_len = 100\n",
    "\n",
    "    model = LyricsClassificationModel(total_words, embed_size, hidden_size, max_sequence_len, num_bands, num_genres,\n",
    "                                      num_subgenres).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    return model, tokenizer, label_encoders, device\n",
    "\n",
    "model_path = 'best_lyrics_classification_model.pth'\n",
    "tokenizer_path = 'tokenizer_claassif.pkl'\n",
    "encoders_path = 'label_encoders.pkl'\n",
    "\n",
    "model, tokenizer, label_encoders, device = load_model_and_encoders(model_path, tokenizer_path, encoders_path)\n",
    "\n",
    "text_to_predict = \"When the quest is over and the battle's won There's a land far to the south where we go to have some fun The wenches they are plenty, the alcohol is free The party lasts all through the night and the alcohol is free\"\n",
    "predicted_band, predicted_genre, predicted_subgenre = predict_genre_subgenre_band(text_to_predict, model, 100,\n",
    "                                                                                  tokenizer, label_encoders, device)\n",
    "print(f\"Predicted Band: {predicted_band}, Predicted Genre: {predicted_genre}, Predicted Subgenre: {predicted_subgenre}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}